{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567aa535",
   "metadata": {},
   "source": [
    "# Auto Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88b87f6",
   "metadata": {},
   "source": [
    "This is a *OpenCV* and *Gdal* for autoregistration of 2 images\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fadc52",
   "metadata": {},
   "source": [
    "1. Load Images and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed64146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\1. PROJECT\\\\satellite_etl\\\\satellite\\\\test'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from osgeo import gdal, osr\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "os.chdir(r\"D:\\1. PROJECT\\satellite_etl\\satellite\\test\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e9c85",
   "metadata": {},
   "source": [
    "1.1 Checks raw bit size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b67d200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw image shape: (2309, 2018) dtype: uint16\n",
      "Ref image shape: (2809, 2550) dtype: uint16\n"
     ]
    }
   ],
   "source": [
    "# Open file and inspect\n",
    "with rasterio.open(\"sss.tif\") as src:\n",
    "    raw = src.read(1)  # read first band\n",
    "    print(\"Raw image shape:\", raw.shape, \"dtype:\", raw.dtype)\n",
    "\n",
    "with rasterio.open(\"oldimage.tif\") as src:\n",
    "    ref = src.read(1)\n",
    "    print(\"Ref image shape:\", ref.shape, \"dtype:\", ref.dtype)\n",
    "  \n",
    "# Converts 16bit to 8bits by normalization  \n",
    "raw = cv2.convertScaleAbs(raw, alpha=(255.0/raw.max()))\n",
    "ref = cv2.convertScaleAbs(ref, alpha=(255.0/ref.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b0fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå raw image (sss.tif) not found or unreadable\n",
      "‚ùå ref image (oldimage.tif) not found or unreadable\n"
     ]
    }
   ],
   "source": [
    "raw = cv2.imread(\"sss.tif\", cv2.IMREAD_GRAYSCALE)\n",
    "ref = cv2.imread(\"oldimage.tif\", cv2.IMREAD_GRAYSCALE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78efa6c",
   "metadata": {},
   "source": [
    "2. Detect Features and Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a633ffc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good matches: 28\n",
      "‚úÖ Alignment done, saved as aligned_opencv.tif\n",
      "üîç Saved debug_matches.png for inspection\n"
     ]
    }
   ],
   "source": [
    "# ORB detector (tuned)\n",
    "orb = cv2.ORB_create(10000, edgeThreshold=15, patchSize=31)\n",
    "\n",
    "# Detect + compute descriptors\n",
    "kp1, des1 = orb.detectAndCompute(raw, None)\n",
    "kp2, des2 = orb.detectAndCompute(ref, None)\n",
    "\n",
    "# Brute-force matcher with KNN\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Lowe's ratio test\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "print(\"Good matches:\", len(good))\n",
    "\n",
    "# Need at least 4 points for homography\n",
    "if len(good) >= 4:\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Homography with RANSAC\n",
    "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "    # Warp raw image to reference\n",
    "    h, w = ref.shape\n",
    "    aligned = cv2.warpPerspective(raw, H, (w, h))\n",
    "    cv2.imwrite(\"aligned_opencv.tif\", aligned)\n",
    "    print(\"‚úÖ Alignment done, saved as aligned_opencv.tif\")\n",
    "\n",
    "    # Debug: draw matches\n",
    "    debug_matches = cv2.drawMatches(raw, kp1, ref, kp2, good[:50], None,\n",
    "                                    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv2.imwrite(\"debug_matches.png\", debug_matches)\n",
    "    print(\"üîç Saved debug_matches.png for inspection\")\n",
    "else:\n",
    "    print(\"‚ùå Not enough good matches for homography\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a36c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_img = cv2.drawMatches(raw, kp1, ref, kp2, good[:50], None, flags=2)\n",
    "cv2.imwrite(\"matches_preview.jpg\", matched_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea27ca5",
   "metadata": {},
   "source": [
    "3. Estimate Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553d9c3a",
   "metadata": {},
   "source": [
    "4. Pass Alignment into GDAL (Georeference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158c7501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved georeferenced.tif with spatial reference from oldimage.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deleo\\miniconda3\\envs\\webgisbackend\\Lib\\site-packages\\osgeo\\gdal.py:311: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use the filename, not the array\n",
    "ref_path = \"oldimage.tif\"\n",
    "aligned_path = \"aligned_opencv.tif\"\n",
    "\n",
    "ref_ds = gdal.Open(ref_path)\n",
    "proj = ref_ds.GetProjection()\n",
    "geotransform = ref_ds.GetGeoTransform()\n",
    "\n",
    "# Open the aligned image (the one from warpPerspective)\n",
    "aligned_ds = gdal.Open(aligned_path)\n",
    "\n",
    "# Save aligned image with reference geoinfo\n",
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "out_ds = driver.CreateCopy(\"georeferenced.tif\", aligned_ds)\n",
    "\n",
    "out_ds.SetProjection(proj)           # assign CRS\n",
    "out_ds.SetGeoTransform(geotransform) # assign geotransform\n",
    "out_ds.FlushCache()\n",
    "\n",
    "print(\"‚úÖ Saved georeferenced.tif with spatial reference from oldimage.tif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c222665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e6d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: D:\\1. PROJECT\\satellite_etl\\satellite\\test\n",
      "Raw: sss.tif  bands=5  shape=(2309, 2018) dtype=uint16\n",
      "Ref: oldimage.tif  shape=(2809, 2550)  crs=ESRI:102457\n",
      "Saved preview for feature-detection: aligned_opencv_preview.tif\n",
      "Good matches: 25\n",
      "Saved debug matches image: debug_matches.png\n",
      "Homography matrix:\n",
      " [[-5.10321727e+00  3.35473958e+00  1.88659914e+03]\n",
      " [-6.23889393e+00  4.20855694e+00  2.17433770e+03]\n",
      " [-2.81387303e-03  1.88157125e-03  1.00000000e+00]]\n",
      "Warping 5 bands from raw size (2309, 2018) to ref size (2809, 2550) ...\n",
      "Warping complete.\n",
      "Saved warped preview (8-bit): warped_preview_8bit.png\n",
      "‚úÖ Saved multi-band georeferenced image: georeferenced.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.transform import Affine\n",
    "from osgeo import gdal\n",
    "\n",
    "# ---------- User settings ----------\n",
    "WORKDIR = r\"D:\\1. PROJECT\\satellite_etl\\satellite\\test\"\n",
    "RAW_PATH = \"sss.tif\"        # source to be aligned (may be multi-band, e.g., 16-bit)\n",
    "REF_PATH = \"oldimage.tif\"   # reference with correct geo-transform & CRS\n",
    "OUT_PATH = \"georeferenced.tif\"\n",
    "DEBUG_MATCHES = \"debug_matches.png\"\n",
    "ALIGNED_PREVIEW = \"aligned_opencv_preview.tif\"  # single-band preview\n",
    "MIN_MATCH_COUNT = 4\n",
    "RATIO_TEST = 0.75\n",
    "# Choose interpolation: cv2.INTER_LINEAR (continuous) or cv2.INTER_NEAREST (categorical)\n",
    "INTERPOLATION = cv2.INTER_LINEAR\n",
    "# -----------------------------------\n",
    "\n",
    "os.chdir(WORKDIR)\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "\n",
    "# Use exceptions for GDAL messages (optional)\n",
    "try:\n",
    "    gdal.UseExceptions()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# --- 1) Read image data (rasterio) ---\n",
    "with rasterio.open(RAW_PATH) as src:\n",
    "    raw_bands = src.read()  # shape (bands, h, w)\n",
    "    raw_profile = src.profile\n",
    "    raw_dtype = src.dtypes[0]\n",
    "    print(f\"Raw: {RAW_PATH}  bands={raw_bands.shape[0]}  shape={raw_bands.shape[1:]} dtype={raw_dtype}\")\n",
    "\n",
    "with rasterio.open(REF_PATH) as ref_src:\n",
    "    ref_band1 = ref_src.read(1)  # single band used as reference for feature detection\n",
    "    ref_transform = ref_src.transform\n",
    "    ref_crs = ref_src.crs\n",
    "    ref_h, ref_w = ref_band1.shape\n",
    "    print(f\"Ref: {REF_PATH}  shape={(ref_h, ref_w)}  crs={ref_crs}\")\n",
    "\n",
    "# --- 2) Prepare grayscale 8-bit images for feature detection ---\n",
    "def to_8bit(img):\n",
    "    \"\"\"Normalize and convert to uint8 for feature detection (handles any dtype).\"\"\"\n",
    "    img = img.astype(\"float32\")\n",
    "    mx = img.max()\n",
    "    if mx == 0:\n",
    "        return np.zeros_like(img, dtype=np.uint8)\n",
    "    out = (img / mx * 255.0).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "# Use the first band of raw for feature detection (but preserve all bands for warping)\n",
    "raw_band_for_feat = raw_bands[0]\n",
    "raw_gray8 = to_8bit(raw_band_for_feat)\n",
    "ref_gray8 = to_8bit(ref_band1)\n",
    "\n",
    "# Save a small preview of the normalized images (optional)\n",
    "cv2.imwrite(ALIGNED_PREVIEW, raw_gray8)\n",
    "print(\"Saved preview for feature-detection:\", ALIGNED_PREVIEW)\n",
    "\n",
    "# --- 3) Feature detection & matching (ORB + KNN + Lowe) ---\n",
    "# Increase ORB features for satellite imagery\n",
    "orb = cv2.ORB_create(nfeatures=100000, edgeThreshold=15, patchSize=31)\n",
    "\n",
    "kp1, des1 = orb.detectAndCompute(raw_gray8, None)\n",
    "kp2, des2 = orb.detectAndCompute(ref_gray8, None)\n",
    "\n",
    "if des1 is None or des2 is None:\n",
    "    raise RuntimeError(\"No descriptors found in one of the images. Try different detector or check input images.\")\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Lowe's ratio test\n",
    "good = []\n",
    "for m_n in matches:\n",
    "    if len(m_n) != 2:\n",
    "        continue\n",
    "    m, n = m_n\n",
    "    if m.distance < RATIO_TEST * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "print(\"Good matches:\", len(good))\n",
    "\n",
    "if len(good) < MIN_MATCH_COUNT:\n",
    "    raise RuntimeError(f\"Not enough good matches ({len(good)}) to compute homography. Try relaxing ratio or using SIFT/AKAZE.\")\n",
    "\n",
    "# Draw debug matches (first 100)\n",
    "dbg_img = cv2.drawMatches(raw_gray8, kp1, ref_gray8, kp2, good[:100], None,\n",
    "                          flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.imwrite(DEBUG_MATCHES, dbg_img)\n",
    "print(\"Saved debug matches image:\", DEBUG_MATCHES)\n",
    "\n",
    "# --- 4) Compute homography (raw -> ref pixel coords) ---\n",
    "src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "if H is None:\n",
    "    raise RuntimeError(\"findHomography failed to produce a matrix.\")\n",
    "\n",
    "print(\"Homography matrix:\\n\", H)\n",
    "\n",
    "# --- 5) Warp each band of the original to reference pixel grid ---\n",
    "# raw_bands shape: (bands, raw_h, raw_w)\n",
    "bands, raw_h, raw_w = raw_bands.shape\n",
    "print(f\"Warping {bands} bands from raw size {(raw_h, raw_w)} to ref size {(ref_h, ref_w)} ...\")\n",
    "\n",
    "warped_bands = np.zeros((bands, ref_h, ref_w), dtype=raw_bands.dtype)\n",
    "\n",
    "for b in range(bands):\n",
    "    band = raw_bands[b]\n",
    "    # OpenCV expects single-channel 2D arrays; preserve dtype (e.g., uint16)\n",
    "    # cv2.warpPerspective will output same dtype as input\n",
    "    warped = cv2.warpPerspective(band, H, (ref_w, ref_h), flags=INTERPOLATION)\n",
    "    warped_bands[b] = warped\n",
    "\n",
    "print(\"Warping complete.\")\n",
    "\n",
    "# Optional: create a quick visual preview (8-bit) of the first warped band\n",
    "warped_preview_8 = to_8bit(warped_bands[0])\n",
    "cv2.imwrite(\"warped_preview_8bit.png\", warped_preview_8)\n",
    "print(\"Saved warped preview (8-bit): warped_preview_8bit.png\")\n",
    "\n",
    "# --- 6) Write multi-band GeoTIFF with reference geo-transform & CRS (rasterio) ---\n",
    "out_profile = raw_profile.copy()\n",
    "out_profile.update({\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"height\": ref_h,\n",
    "    \"width\": ref_w,\n",
    "    \"count\": bands,\n",
    "    \"dtype\": raw_bands.dtype,\n",
    "    \"transform\": ref_transform,\n",
    "    \"crs\": ref_crs,\n",
    "    \"compress\": \"lzw\",\n",
    "})\n",
    "\n",
    "with rasterio.open(OUT_PATH, \"w\", **out_profile) as dst:\n",
    "    dst.write(warped_bands)\n",
    "    # if there is nodata in the original profile, also set it:\n",
    "    if \"nodata\" in raw_profile and raw_profile[\"nodata\"] is not None:\n",
    "        dst.nodata = raw_profile[\"nodata\"]\n",
    "\n",
    "print(f\"‚úÖ Saved multi-band georeferenced image: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec56f3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: D:\\1. PROJECT\\satellite_etl\\satellite\\test2\n",
      "Raw: sss.tif  bands=5  shape=(2309, 2018) dtype=uint16\n",
      "Ref: oldimage.tif  shape=(2809, 2550)  crs=ESRI:102457\n",
      "Saved preview for feature-detection: aligned_opencv_preview.tif\n",
      "Good matches: 31\n",
      "Saved debug matches image: debug_matches.png\n",
      "Homography matrix:\n",
      " [[-1.95431806e+00  6.94694982e-01  2.33320680e+03]\n",
      " [-1.61250824e+00  5.72370270e-01  1.92594337e+03]\n",
      " [-8.37444740e-04  2.97508979e-04  1.00000000e+00]]\n",
      "Warping 5 bands from raw size (2309, 2018) to ref size (2809, 2550) ...\n",
      "Warping complete.\n",
      "Saved warped preview (8-bit): warped_preview_8bit.png\n",
      "‚úÖ Saved multi-band georeferenced image: georeferenced.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.transform import Affine\n",
    "from osgeo import gdal\n",
    "\n",
    "# ---------- User settings ----------\n",
    "WORKDIR = r\"D:\\1. PROJECT\\satellite_etl\\satellite\\test2\"\n",
    "RAW_PATH = \"sss.tif\"        # source to be aligned (may be multi-band, e.g., 16-bit)\n",
    "REF_PATH = \"oldimage.tif\"   # reference with correct geo-transform & CRS\n",
    "OUT_PATH = \"georeferenced.tif\"\n",
    "DEBUG_MATCHES = \"debug_matches.png\"\n",
    "ALIGNED_PREVIEW = \"aligned_opencv_preview.tif\"  # single-band preview\n",
    "MIN_MATCH_COUNT = 4\n",
    "RATIO_TEST = 0.75\n",
    "# Choose interpolation: cv2.INTER_LINEAR (continuous) or cv2.INTER_NEAREST (categorical)\n",
    "INTERPOLATION = cv2.INTER_LINEAR\n",
    "# -----------------------------------\n",
    "\n",
    "os.chdir(WORKDIR)\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "\n",
    "# Use exceptions for GDAL messages (optional)\n",
    "try:\n",
    "    gdal.UseExceptions()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# --- 1) Read image data (rasterio) ---\n",
    "with rasterio.open(RAW_PATH) as src:\n",
    "    raw_bands = src.read()  # shape (bands, h, w)\n",
    "    raw_profile = src.profile\n",
    "    raw_dtype = src.dtypes[0]\n",
    "    print(f\"Raw: {RAW_PATH}  bands={raw_bands.shape[0]}  shape={raw_bands.shape[1:]} dtype={raw_dtype}\")\n",
    "\n",
    "with rasterio.open(REF_PATH) as ref_src:\n",
    "    ref_band1 = ref_src.read(1)  # single band used as reference for feature detection\n",
    "    ref_transform = ref_src.transform\n",
    "    ref_crs = ref_src.crs\n",
    "    ref_h, ref_w = ref_band1.shape\n",
    "    print(f\"Ref: {REF_PATH}  shape={(ref_h, ref_w)}  crs={ref_crs}\")\n",
    "\n",
    "# --- 2) Prepare grayscale 8-bit images for feature detection ---\n",
    "def to_8bit(img):\n",
    "    \"\"\"Normalize and convert to uint8 for feature detection (handles any dtype).\"\"\"\n",
    "    img = img.astype(\"float32\")\n",
    "    mx = img.max()\n",
    "    if mx == 0:\n",
    "        return np.zeros_like(img, dtype=np.uint8)\n",
    "    out = (img / mx * 255.0).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "# Use the first band of raw for feature detection (but preserve all bands for warping)\n",
    "raw_band_for_feat = raw_bands[0]\n",
    "raw_gray8 = to_8bit(raw_band_for_feat)\n",
    "ref_gray8 = to_8bit(ref_band1)\n",
    "\n",
    "# Save a small preview of the normalized images (optional)\n",
    "cv2.imwrite(ALIGNED_PREVIEW, raw_gray8)\n",
    "print(\"Saved preview for feature-detection:\", ALIGNED_PREVIEW)\n",
    "\n",
    "# --- 3) Feature detection & matching (ORB + KNN + Lowe) ---\n",
    "# Option 1: AKAZE (fast, works on non-linear scale space, good for textured imagery)\n",
    "# detector = cv2.AKAZE_create()\n",
    "\n",
    "# Option 2: SIFT (robust, scale/rotation invariant, but slower)\n",
    "detector = cv2.SIFT_create(nfeatures=10000)   \n",
    "\n",
    "\n",
    "kp1, des1 = detector.detectAndCompute(raw_gray8, None)\n",
    "kp2, des2 = detector.detectAndCompute(ref_gray8, None)\n",
    "\n",
    "if des1 is None or des2 is None:\n",
    "    raise RuntimeError(\"No descriptors found in one of the images. Try another detector.\")\n",
    "\n",
    "# Select matcher norm based on descriptor dtype\n",
    "if des1.dtype == np.uint8:\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "else:\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "\n",
    "# Lowe's ratio test\n",
    "good = []\n",
    "for m_n in matches:\n",
    "    if len(m_n) != 2:\n",
    "        continue\n",
    "    m, n = m_n\n",
    "    if m.distance < RATIO_TEST * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "print(\"Good matches:\", len(good))\n",
    "\n",
    "\n",
    "# Draw debug matches (first 100)\n",
    "dbg_img = cv2.drawMatches(raw_gray8, kp1, ref_gray8, kp2, good[:100], None,\n",
    "                          flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.imwrite(DEBUG_MATCHES, dbg_img)\n",
    "print(\"Saved debug matches image:\", DEBUG_MATCHES)\n",
    "\n",
    "# --- 4) Compute homography (raw -> ref pixel coords) ---\n",
    "src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "if H is None:\n",
    "    raise RuntimeError(\"findHomography failed to produce a matrix.\")\n",
    "\n",
    "print(\"Homography matrix:\\n\", H)\n",
    "\n",
    "# --- 5) Warp each band of the original to reference pixel grid ---\n",
    "# raw_bands shape: (bands, raw_h, raw_w)\n",
    "bands, raw_h, raw_w = raw_bands.shape\n",
    "print(f\"Warping {bands} bands from raw size {(raw_h, raw_w)} to ref size {(ref_h, ref_w)} ...\")\n",
    "\n",
    "warped_bands = np.zeros((bands, ref_h, ref_w), dtype=raw_bands.dtype)\n",
    "\n",
    "for b in range(bands):\n",
    "    band = raw_bands[b]\n",
    "    # OpenCV expects single-channel 2D arrays; preserve dtype (e.g., uint16)\n",
    "    # cv2.warpPerspective will output same dtype as input\n",
    "    warped = cv2.warpPerspective(band, H, (ref_w, ref_h), flags=INTERPOLATION)\n",
    "    warped_bands[b] = warped\n",
    "\n",
    "print(\"Warping complete.\")\n",
    "\n",
    "# Optional: create a quick visual preview (8-bit) of the first warped band\n",
    "warped_preview_8 = to_8bit(warped_bands[0])\n",
    "cv2.imwrite(\"warped_preview_8bit.png\", warped_preview_8)\n",
    "print(\"Saved warped preview (8-bit): warped_preview_8bit.png\")\n",
    "\n",
    "# --- 6) Write multi-band GeoTIFF with reference geo-transform & CRS (rasterio) ---\n",
    "out_profile = raw_profile.copy()\n",
    "out_profile.update({\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"height\": ref_h,\n",
    "    \"width\": ref_w,\n",
    "    \"count\": bands,\n",
    "    \"dtype\": raw_bands.dtype,\n",
    "    \"transform\": ref_transform,\n",
    "    \"crs\": ref_crs,\n",
    "    \"compress\": \"lzw\",\n",
    "})\n",
    "\n",
    "with rasterio.open(OUT_PATH, \"w\", **out_profile) as dst:\n",
    "    dst.write(warped_bands)\n",
    "    # if there is nodata in the original profile, also set it:\n",
    "    if \"nodata\" in raw_profile and raw_profile[\"nodata\"] is not None:\n",
    "        dst.nodata = raw_profile[\"nodata\"]\n",
    "\n",
    "print(f\"‚úÖ Saved multi-band georeferenced image: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe17e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webgisbackend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
